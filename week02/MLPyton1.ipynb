{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tarea aplicarás lo visto en clase para implementar **Leave-One-Out Cross Validation** para seleccionar el mejor hyperparámetro de una lista de datos y validadremos nuestra decisión considerando **k-fold Cross Validation**.\n",
    "\n",
    "![Amsterdam](https://www.iamsterdam.com/media/canals-and-cityscapes/l-c-dentists-nc.jpg?h=328&w=580&as=false&iar=true)\n",
    "\n",
    "Supongamos te quieres ir de viaje a Amsterdam y quedarte en algún lugar usando Airbnb. Para estimar cuanto te costaría el viaje decides usar un modelo lineal para saber cuanto afecta el precio dada una lista de *features*. Para tu suerte, encuentras una [base de datos](http://tomslee.net/airbnb-data-collection-get-the-data) con justo lo que necesitas. Evidentemente, la mejor manera de tomar esta decisión, para un(a) ñoño(a) como tú es usando machine learning.\n",
    "\n",
    "Iniciamos nuestro análisis cargando las funciones que necesitarás para completar la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmin\n",
    "from math import sqrt\n",
    "from statistics import mean, stdev\n",
    "from cv_utls import (load_airbnb,\n",
    "                     train_cv_test_split,\n",
    "                     get_feature_targets,\n",
    "                     plot_cost,\n",
    "                     estimate_theta,\n",
    "                     make_train_fold,\n",
    "                     l2_norm,\n",
    "                     create_k_folds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos cargando la base de datos y limpiandola. Correr la siguiente línea baja los datos, los carga y nos regresa un tuple donde el primer elemento es la base de datos y, la segunda, el nombre de las variables con las cuáles predeciremos el costo.\n",
    "\n",
    "Al cargar todos los datos, deberías ver un mapa con los precios para cada punto a considerar en nuestra base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb, airbnb_features = load_airbnb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr la siguiente línea de codigo veremos los *features* de nuestro modelo. Una cosa importante a notar son las variables `neighborhood_xxx` y `room_type_xxx`. Este es un ejemplo de *One-Hot-Encoding*.\n",
    "\n",
    "Al tener una columna de variables categóricas, digámos:\n",
    "\n",
    "|obs| feat |\n",
    "|--|-----| \n",
    "|o1|A |\n",
    "|o2|B |\n",
    "|o3|C |\n",
    "|o4|C |\n",
    "|o5|B |\n",
    "\n",
    "Podemos modificar esta columna para poder ingresarla a nuestro modelo de machine learning creando 3 nuevos *features*, uno para cada cada categoría. Evidentemente, una observación solo tendrá una clase asignada, es decir, un solo uno seguido de una fila de ceros. En nuestro ejemplo anterior, esto quedaría como sigue:\n",
    "\n",
    "|obs|feat_A|feat_B|feat_C|\n",
    "|--|-----|-----|-----|\n",
    "|o1|1|0|0|\n",
    "|o2|0|1|0|\n",
    "|o3|0|0|1|\n",
    "|o4|0|0|1|\n",
    "|o5|0|1|0|\n",
    "\n",
    "De esta manera, ya podemos entrenar nuestro modelo usando variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `train_cv_test_split` separa la base de datos en 3 componentes: train, cv y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, cv, test = train_cv_test_split(airbnb)\n",
    "features_targets = get_feature_targets(train, cv, test)\n",
    "X_train, X_cv, X_test = features_targets[\"features\"]\n",
    "y_train, y_cv, y_test = features_targets[\"targets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:crimson\"> Ejercicio </h2>\n",
    "Implementa *Leave-One-Out Cross Validation*.\n",
    "\n",
    "Empecemos por elegir el mejor hyperparámetro para nuestro modelo. Tu trabajo es completar la función `loocv` considerando la metodología vista en clase para este tipo de CV.\n",
    "\n",
    "Para completar la función deberás usar las funciones\n",
    "* `estimate_theta(X, y, lmbda)`: esta fución toma una serie de *features* $X$, *targets* $y$ y lmbda como factor de regularización. Date cuenta que ya tienes $X$, y $y$. Tu tarea es elegir la adecuada entre las variables que cargamos en la celda de arriba.\n",
    "* `l2_norm(theta, X, y)`: Calcula el error considerando una norma en $L_2$ como vista en clase. Cuando cálcules cada Ji, por esta ocasión, divide el resultado de `l2_norm` por `nexamples` para normalizar el resultado. (El mínimo no se ve afectado por esta transformación)\n",
    "\n",
    "**Nota**, Al igual que con loops, una función en python se declará con dos puntos después de los argumentos y se dejan cuatro espacios para toda linea subsecuente que pertencezca a la función. No te preocupes, veremos los detalles de la función en la clase de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(lambdas, X_train, X_cv, y_train, y_cv):\n",
    "    \"\"\"\n",
    "    Función para estimar el mejor hyperparámetro\n",
    "    de una regressión lineal con penalización en L2\n",
    "    (ridge regression) usando el método\n",
    "    Leave-One-Out Cross Validation\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    lambdas: list\n",
    "        Lista de posibles hyperparámetros que mejor\n",
    "        generalizen X_cv\n",
    "    \"\"\"\n",
    "    nexamples = X_cv.shape[1]\n",
    "    ### Completar Código ##\n",
    "    # Inicializa las variables 'Jcv' y 'thetas' como listas\n",
    "    # vacías (aquí guardaremos las variables para tomar las decisiones)\n",
    "    Jcv = None\n",
    "    thetas = None\n",
    "    # Itera sobre cada lambda_i dentro de la lista de lambdas, recuerda\n",
    "    # usar las funciones estimate_theta y l2_norm y guardar tus costos en\n",
    "    # Jcv y thetas\n",
    "    \n",
    "    return Jcv, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [l/100 for l in range(15)]\n",
    "Js, thetas = loocv(lambdas, X_train, X_cv, y_train, y_cv)\n",
    "# Grafica la función objetivo (J) como función\n",
    "# del hyperparámetro lambda\n",
    "plot_cost(lambdas, Js)\n",
    "\n",
    "\n",
    "icv = argmin(Js)\n",
    "theta_cv = thetas[icv]\n",
    "print(\"El índice óptimo es\", icv)\n",
    "print(\"Lambda óptima es\", lambdas[icv])\n",
    "print(\"J(theta) óptima es {:,.2f}\".format(Js[icv]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado esperado**\n",
    "```\n",
    "El índice óptimo es 11\n",
    "Lambda óptima es 0.11\n",
    "J(theta) óptima es 2,282.70\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:crimson\"> Ejercicio </h2>\n",
    "Corre la siguiente linea de código e interpreta tus resultados. Considera lo siguiente\n",
    "\n",
    "1) ¿qué te dice cada uno de los coeficientes óptimos respecto a elegir un lugar para quedarse en Amsterdam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta, name in zip(theta_cv.ravel(), airbnb_features):\n",
    "    print(\"{t:12,.2f} | {n}\".format(t=theta, n=name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:crimson\"> Ejercicio </h2>\n",
    "Implementa *K-fold Cross Validation*.\n",
    "\n",
    "Una vez elegido un modelo, nuestro tabajo ahora es saber que tan confiables son los parámetros encontrados.\n",
    "Completa la función `kfoldcv` considerando la metodología en clase para este tipo de CV.\n",
    "\n",
    "Recuerda que, para k-fold cv, ya asumimos una $\\lambda$ y queremos probar su confiablidad probandola sobre cada base de datos. Para completar esta tarea tienes las funciones\n",
    "\n",
    "* `create_k_folds(data, nfolds)` toma una base de datos a entrenar (*train* en este caso) y nos crea una lista de tuples nfolds pares con (X, y) valores para entrenar\n",
    "* `make_rtrain_fold(folds, k)` toma una lista de tuples con (X, y) y un índice $k$, nos regresa una sola base de datos **sin** considerar el $k$-ésimo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldcv(lmbda, data, nfolds):\n",
    "    \"\"\"\n",
    "    Función para estimar el mejor hyperparámetro\n",
    "    de una regressión lineal con penalización en L2\n",
    "    (ridge regression) usando el método de K-fold CV\n",
    "    \"\"\"\n",
    "    # Crea 'nfolds' usando la función create_k_folds\n",
    "    folds = create_k_folds(data, nfolds)\n",
    "    Js, thetas = [], []\n",
    "    for k in range(nfolds):\n",
    "        # Obtén el el 'training dataset' omitiendo el k-ésimo\n",
    "        # elemento en folds (considera la función make_train_fold)\n",
    "        X_train, y_train = None\n",
    "        # Obtén el k-ésimo fold dentro de folds\n",
    "        X_cv, y_cv = None\n",
    "        nexamples = X_cv.shape[1]\n",
    "        # Estima theta^* considerando el hyperparámetros lmbda\n",
    "        theta_i = None\n",
    "        # Estima el error J. Recuerda dividir el costo entre\n",
    "        # 'examples' para una interpretación respecto a la media.\n",
    "        # De igual manera, calcula la raíz cuadrada de de Ji\n",
    "        Ji = None\n",
    "        Js.append(Ji)\n",
    "        # Agregamos cada parámetro estimado a la lista\n",
    "        # de estimaciones totales\n",
    "        thetas.append(theta_i.ravel().tolist())\n",
    "    \n",
    "    return Js, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jfolds, thetas = kfoldcv(0.11, train, 100)\n",
    "\n",
    "# Calcula el el promedio de los errores estándard (Jfolds)\n",
    "# usando la función 'mean'. Guardala dentro de la\n",
    "# variable 'meanerr'\n",
    "meanerr = None\n",
    "\n",
    "# Calcula la desviación estándard de los errores estándard (Jfolds)\n",
    "# usando la función 'stdev'. Guárdala dentro de la variable\n",
    "# stdevs\n",
    "stdevs = None\n",
    "\n",
    "print(\"La média los errores estándard fueron {:,.2f}\".format(meanerr))\n",
    "print(\"La desviación promedio de los errores estándard fueron {:,.2f}\".format(stdevs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado esperado**\n",
    "\n",
    "```\n",
    "La média los errores estándard fueron 19.47\n",
    "La desviación promedio de los errores estándard fueron 26.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:crimson\">Ejercicio*</h2>\n",
    "Considerando la lista `thetas` (recordemos que esta es una lista de listas con la estimación de cada parámetro), cálcula la `theta_i` promedio y su desviación estándard para toda `i`. Seguido de esto, presenta un intervalo de confianza a una desviación estándard para cada parámetro.\n",
    "\n",
    "¿Qué tan confiables son los resultados? Argumenta tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado Ejemplo**\n",
    "\n",
    "```\n",
    "   135.14 ± 959.05: bias\n",
    "    14.98 ±  33.02: accommodates\n",
    "    14.35 ±   9.84: bedrooms\n",
    "    -3.55 ±   9.37: minstay\n",
    "     5.58 ±  20.29: overall_satisfaction\n",
    "    -5.37 ±  13.41: reviews\n",
    "   -21.73 ± 122.90: neighborhood_BijlmerCentrum\n",
    "   -14.77 ±  84.64: neighborhood_BijlmerOost\n",
    "    -4.58 ±  87.45: neighborhood_BosenLommer\n",
    "     7.13 ± 103.25: neighborhood_Buitenveldert_Zuidas\n",
    "    51.08 ± 120.96: neighborhood_CentrumOost\n",
    "    59.71 ± 109.05: neighborhood_CentrumWest\n",
    "     2.35 ± 109.63: neighborhood_DeAker_NieuwSloten\n",
    "    24.98 ± 131.17: neighborhood_DeBaarsjes_OudWest\n",
    "    27.92 ± 128.60: neighborhood_DePijp_Rivierenbuurt\n",
    "   -11.72 ± 149.29: neighborhood_Gaasperdam_Driemond\n",
    "    -4.19 ±  85.82: neighborhood_Geuzenveld_Slotermeer\n",
    "    -3.51 ±  81.30: neighborhood_Ijburg_EilandZeeburg\n",
    "    27.80 ±  82.39: neighborhood_Noord-West_Noord-Midden\n",
    "   -30.20 ±  89.31: neighborhood_NoordOost\n",
    "   -18.75 ±  96.13: neighborhood_NoordWest\n",
    "     1.16 ±  76.74: neighborhood_OostelijkHavengebied_IndischeBuurt\n",
    "   -13.80 ±  88.04: neighborhood_Osdorp\n",
    "    -4.06 ±  92.21: neighborhood_OudNoord\n",
    "     3.59 ±  60.84: neighborhood_OudOost\n",
    "   -10.87 ±  62.11: neighborhood_Slotervaart\n",
    "     5.05 ±  76.97: neighborhood_Watergraafsmeer\n",
    "     6.30 ±  74.24: neighborhood_Westerpark\n",
    "    13.97 ± 110.08: neighborhood_Westpoort\n",
    "   -49.31 ± 771.05: room_type_Entire_homeapt\n",
    "   -80.99 ± 676.84: room_type_Private_room\n",
    "  -114.85 ± 565.26: room_type_Shared_room\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:crimson\">Ejercicio</h2>\n",
    "Como ejercicio final, calcula el costo $J(\\theta|X^{test}, y^{test})$ considerando el test set. Recuerda dividir tu costo enttre el número de ejemplos guardado en la variable `ntest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = X_test.shape[1]\n",
    "cost_test = None\n",
    "cost_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado esperado**\n",
    "```\n",
    "2271.8588520664762\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
